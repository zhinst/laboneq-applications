{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d15d4ecd",
   "metadata": {},
   "source": [
    "# Experiment Workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddad75a6",
   "metadata": {},
   "source": [
    "This tutorial shows how to use the experiments in the Applications Library, which are all implemented using the [Workflow objects of LabOne Q](https://docs.zhinst.com/labone_q_user_manual/core/functionality_and_concepts/07_workflow/concepts/index.html).\n",
    "\n",
    "A `Workflow` is a collection of logically connected `Tasks` or other workflows whose inputs and outputs depend on each other. The parent `Workflow` automatically distributes options to all its `Tasks` and saves their inputs and outputs. To learn more about `Tasks`, check out the [tutorial on using Tasks in LabOne Q](https://docs.zhinst.com/labone_q_user_manual/core/functionality_and_concepts/07_workflow/tutorials/00_tasks.html).\n",
    "\n",
    "When instantiated, a function decorated with  `@workflow` builds a graph of tasks that will be executed later. This graph may be inspected. The graph of tasks is not executed directly by Python, but by a workflow engine provided by LabOne Q. To learn more about workflows, tasks, options, and the saving functionality of workflows check out the [tutorials in the LabOne Q core manual](https://docs.zhinst.com/labone_q_user_manual/core/functionality_and_concepts/07_workflow/concepts/index.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8f4395-fb25-43e0-8841-44ae63ccab82",
   "metadata": {},
   "source": [
    "Experiment `Workflows` have the standard tasks shown in the image below:\n",
    "\n",
    "<img src=\"../../how-to-guides/images/workflows.svg\" width=\"200\">\n",
    "\n",
    "Let's see what these tasks are:\n",
    "\n",
    "- `create_experiment` for creating the experimental pulse sequence as an instance of the LabOne Q [Experiment class](https://docs.zhinst.com/labone_q_user_manual/core/functionality_and_concepts/05_experiment/concepts/index.html).\n",
    "  This task is typically unique for every experiment.\n",
    "- `compile_experiment` for compiling the `Experiment` returned by `create_experiment`.\n",
    "- `run_experiment` for running the `CompiledExperiment` returned by `compile_experiment`.\n",
    "- `analysis_workflow` for running the analysis on the `RunExperimentResults` returned by `run_experiment`.\n",
    "- `update_qpu` for updating the relevant quantum parameters with the values found in the `analysis_workflow`.\n",
    "\n",
    "The `Tasks` `compile_experiment`, `run_experiment`, and `update_qpu` can be used for all experiments, because they are independent of the details of the experiment being implemented. `create_experiment` and `analysis_workflow` typically need to be implemented for every experiment.\n",
    "\n",
    "Experiment `Workflows` also have a few standard input parameters: \n",
    "\n",
    "- `session`: a LabOne Q `Session`.\n",
    "- `qpu`: a `QPU` object containing the most up-to-date knowledge about the parameters of the quantum processor.\n",
    "- `qubits`: the list of qubit instances on the `qpu`, on which to run the experiment.\n",
    "- (the sweep points if relevant)\n",
    "- `temporary_parameters` for temporarily overwriting the quantum element and topology edge parameters during the execution of the experiment.\n",
    "- `options`: an instance of `WorkflowOptions`.\n",
    "\n",
    "Let's look at all of this in more detail."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60792fb3",
   "metadata": {},
   "source": [
    "## Create a device setup and session\n",
    "\n",
    "First, we create a LabOne Q `DeviceSetup`, and 6 `TunableTransmonQubits` and their corresponding `TunableTransmonOperations` using the demo `QuantumPlatform` provided by the Applications Library for running in emulation mode. See the [Getting Started tutorial](https://docs.zhinst.com/labone_q_user_manual/applications_library/tutorials/sources/getting_started.html) for more details about the `QuantumPlatform` and how to create your experimental setup and prepare it for running experiments."
   ]
  },
  {
   "cell_type": "code",
   "id": "cc4aa502",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "from laboneq.core.exceptions import LabOneQException\n",
    "from laboneq.simple import *\n",
    "\n",
    "from laboneq_applications.qpu_types.tunable_transmon import demo_platform"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "dc19f7b9",
   "metadata": {},
   "source": [
    "# Create a demonstration QuantumPlatform for a tunable-transmon QPU:\n",
    "qt_platform = demo_platform(n_qubits=6)\n",
    "\n",
    "# The platform contains a setup, which is an ordinary LabOne Q DeviceSetup:\n",
    "setup = qt_platform.setup\n",
    "\n",
    "# And a tunable-transmon QPU:\n",
    "qpu = qt_platform.qpu\n",
    "\n",
    "# Inside the QPU, we have quantum elements, which is a list of six LabOne Q Application\n",
    "# Library TunableTransmonQubit qubits:\n",
    "qubits = qpu.quantum_elements"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "87140c58",
   "metadata": {},
   "source": [
    "session = Session(setup)\n",
    "session.connect(do_emulation=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a5fb06d0-c819-44a5-9aca-5b4aedebb3be",
   "metadata": {},
   "source": [
    "## Create a FolderStore for Saving Data\n",
    "\n",
    "The experiment `Workflows` can automatically save the inputs and outputs of all their tasks to the folder path we specify when instantiating the [FolderStore](https://docs.zhinst.com/labone_q_user_manual/applications_library/tutorials/sources/logbooks.html#the-folderstore). Here, we choose the current working directory."
   ]
  },
  {
   "cell_type": "code",
   "id": "82a8df8d-6a26-486a-a101-12579a31e5d0",
   "metadata": {},
   "source": [
    "# import FolderStore from the `workflow` namespace of LabOne Q, which was imported\n",
    "# from `laboneq.simple`\n",
    "from pathlib import Path\n",
    "\n",
    "folder_store = workflow.logbook.FolderStore(Path.cwd())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "4af6552c-d57b-482d-b1af-c19262260b4f",
   "metadata": {},
   "source": [
    "We disable saving in this tutorial. To enable it, simply run `folder_store.activate()`."
   ]
  },
  {
   "cell_type": "code",
   "id": "eba1c5dc-13e7-486c-bb71-af7e38579b93",
   "metadata": {},
   "source": [
    "folder_store.deactivate()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "26d5c1b6-14c2-4590-a211-b73f7241a310",
   "metadata": {},
   "source": [
    "## Optional: Configure the LoggingStore\n",
    "\n",
    "You can also activate/deactivate the `LoggingStore`, which is used for displaying the `Workflow` logging information in the notebook; see again the [tutorial on Recording Experiment Workflow Results](https://docs.zhinst.com/labone_q_user_manual/applications_library/tutorials/sources/logbooks.html) for details. \n",
    "\n",
    "Displaying the `Workflow` logging information is activated by default, but here we deactivate it to shorten the outputs, which are not very meaningful in emulation mode. \n",
    "\n",
    "**We recommend that you do not deactivate the Workflow logging in practice.**"
   ]
  },
  {
   "cell_type": "code",
   "id": "5399f28f-e841-453a-a1ee-49adbe490e4c",
   "metadata": {},
   "source": [
    "from laboneq.workflow.logbook import LoggingStore\n",
    "\n",
    "logging_store = LoggingStore()\n",
    "logging_store.deactivate()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e6b32513",
   "metadata": {},
   "source": [
    "## Inspect an experiment Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1806192c",
   "metadata": {},
   "source": [
    "Let's start by inspecting the experiment `Workflow` for the Ramsey experiment."
   ]
  },
  {
   "cell_type": "code",
   "id": "45ac11f0",
   "metadata": {},
   "source": [
    "from laboneq_applications.experiments import ramsey"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f1e132f5",
   "metadata": {},
   "source": "Inspect the source code of the `ramsey` `Workflow` to see that the tasks follow the standard structure and logic of experiment workflows shown above. Notice that the workflow uses special constructions for conditional logic (`with workflow.if_(condition)`). Have a look at the [Workflow syntax tutorial](https://docs.zhinst.com/labone_q_user_manual/core/functionality_and_concepts/07_workflow/tutorials/02_workflow_syntax.html) to learn more about the syntax used by `Workflows`."
  },
  {
   "cell_type": "code",
   "id": "11d8f122",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "ramsey.experiment_workflow.src"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a612716e",
   "metadata": {},
   "source": [
    "## Instantiate the experiment Workflow\n",
    "\n",
    "Let's instantiate the `ramsey` `Workflow` for one single qubit. \n",
    "\n",
    "Note, instantiating the `Workflow` does not run it. Instantiation only resolves the dependencies of the tasks within the workflow."
   ]
  },
  {
   "cell_type": "code",
   "id": "17e5178a",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "experiment_workflow = ramsey.experiment_workflow(\n",
    "    session=session,\n",
    "    qpu=qpu,\n",
    "    qubits=qubits[0],\n",
    "    delays=np.linspace(0, 20e-6, 51),\n",
    "    detunings=0.67e6,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "4b95ae6d-4331-41c3-9c07-bcaf0bdf3dae",
   "metadata": {},
   "source": [
    "Inspect the tree display of the built dependency graph:"
   ]
  },
  {
   "cell_type": "code",
   "id": "3544a7ca-74c0-4dd6-9718-568a3db79e4e",
   "metadata": {},
   "source": [
    "experiment_workflow.graph.tree"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "82b15636-e9cc-416e-9ebb-75860f4d0e70",
   "metadata": {},
   "source": [
    "## Run the experiment Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d09bd0-bd14-4e76-824e-d67a85965d47",
   "metadata": {},
   "source": [
    "To execute the experiment `Workflow`, we call its `run()` method:"
   ]
  },
  {
   "cell_type": "code",
   "id": "2ab8a421-4b45-4f2b-86c7-d58deefef11f",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "workflow_result = experiment_workflow.run()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ef37f30d",
   "metadata": {},
   "source": [
    "workflow_result.tasks"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "6570022d",
   "metadata": {},
   "source": [
    "## Inspect an executed experiment Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf21953e-c3e2-47b9-b9d9-28d34e922336",
   "metadata": {},
   "source": [
    "Now that the `Workflow` has run, we can inspect its inputs and outputs, as well as the inputs and outputs of all its tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9db2493-af4b-4c90-82e6-13a1b073c12c",
   "metadata": {},
   "source": [
    "### Workflow inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b26a17",
   "metadata": {},
   "source": [
    "Let's first inspect the input parameters of the `ramsey` `Workflow`"
   ]
  },
  {
   "cell_type": "code",
   "id": "88bd3d2b",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "workflow_result.input"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "bfc3ce3f-b9e7-46ae-93c7-306233b114d8",
   "metadata": {},
   "source": [
    "### Workflow tasks"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Inspect the tasks of the `Workflow`. Notice that the `update_qpu` task does not appear in this task list. This is because the updating functionality is disabled by default. We will see later how to enable it using the options.",
   "id": "45450ae2aae5dfb8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "for t in workflow_result.tasks:\n",
    "    print(t)"
   ],
   "id": "78a9c8ca18294b15"
  },
  {
   "cell_type": "markdown",
   "id": "9d9c1aec",
   "metadata": {},
   "source": [
    "Inspect the source code of the `create_experiment` task to see how the experiment pulse sequence was created:"
   ]
  },
  {
   "cell_type": "code",
   "id": "f836c0b5",
   "metadata": {},
   "source": [
    "workflow_result.tasks[\"compile_experiment\"].src"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "86de4bb9",
   "metadata": {},
   "source": [
    "workflow_result.tasks[\"compile_experiment\"]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ffc73b31",
   "metadata": {},
   "source": [
    "workflow_result.tasks[\"create_experiment\"].src"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d9210205",
   "metadata": {},
   "source": [
    "The LabOne Q `Experiment` object returned by the `create_experiment` task is found in the output of this task:\n",
    "\n",
    "```python\n",
    "workflow_result.tasks[\"create_experiment\"].output\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3403cfa5-e619-4e52-bba7-517ac25ced1a",
   "metadata": {},
   "source": [
    "Inspect the pulse sequence using `plot_simulation` and the LabOne Q `CompiledExperiment` object returned by the `compile_experiment` task:"
   ]
  },
  {
   "cell_type": "code",
   "id": "3be76a24",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "from laboneq.contrib.example_helpers.plotting.plot_helpers import plot_simulation\n",
    "\n",
    "plot_simulation(\n",
    "    workflow_result.tasks[\"compile_experiment\"].output,\n",
    "    signal_names_to_show=[\"drive\", \"measure\"],\n",
    "    start_time=0,\n",
    "    length=50e-6,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "bd85e2aa-f3d1-4b6d-837b-6b690a1cce54",
   "metadata": {},
   "source": [
    "### Workflow output - acquired data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de11d35",
   "metadata": {},
   "source": [
    "Inspect the `RunExperimentResults` containing the acquired data. The `RunExperimentResults` can be accessed either from the output of the `Workflow`, or from the output of the `run_experiment` tasks:"
   ]
  },
  {
   "cell_type": "code",
   "id": "09c44f70-5b4d-469c-a268-21cf9c6f0aef",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "acquired_data = workflow_result.output\n",
    "acquired_data"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "fa96bab9",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "workflow_result.tasks[\"run_experiment\"].output"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "52952616-da90-4147-886c-93e196a8b13e",
   "metadata": {},
   "source": [
    "The information in the `RunExperimentResults` object can be accessed both via standard Python dictionary notation and the dot-notation at any level of the nested structure:"
   ]
  },
  {
   "cell_type": "code",
   "id": "26cd4707-5466-4aff-8738-0fee598023ae",
   "metadata": {},
   "source": [
    "acquired_data.q0.result"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8af60f22",
   "metadata": {},
   "source": [
    "acquired_data[\"q0\"].result"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "fc3103be-f228-4fe8-9b41-0474612663f8",
   "metadata": {},
   "source": [
    "### Analysis Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c50a8f-9f72-4259-9464-a1b79f3e5aa2",
   "metadata": {},
   "source": [
    "Let's also inspect the Ramsey analysis `Workflow` executed as part of the experiment `Workflow`. First, let's look at the source code. The Ramsey analysis workflow contains the following tasks:\n",
    "\n",
    "\n",
    "- `calculate_qubit_population` for interpreting the raw data into qubit population.\n",
    "- `fit_data` for fitting a cosine module to the qubit population as a function of the pulse amplitude.\n",
    "- `extract_qubit_parameters` for extracting the new qubit frequency and the $T_2^*$ value from the exponentially decaying cosine fit.\n",
    "- `plot_raw_complex_data_1d` for plotting the raw data.\n",
    "- `plot_population` for plotting the qubit population and the fit results."
   ]
  },
  {
   "cell_type": "code",
   "id": "638a9c78-0de8-4064-a005-a5e454c6c915",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "ramsey.analysis_workflow.src"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1e469932-40cf-4744-aa61-4edd9dfb1a58",
   "metadata": {},
   "source": [
    "Let's check that these tasks were actually run in the analysis workflow:"
   ]
  },
  {
   "cell_type": "code",
   "id": "729cf43f-2659-49c9-b4d2-67bc396e55c0",
   "metadata": {},
   "source": [
    "analysis_workflow_results = workflow_result.tasks[\"analysis_workflow\"]\n",
    "for t in analysis_workflow_results.tasks:\n",
    "    print(t)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "06cd4929-c918-485a-9b02-e2a240726982",
   "metadata": {},
   "source": [
    "All the inputs and outputs of these tasks can be inspected. For example, let's get back the fit results returned by the `fit_data` task and the final Ramsey figures returned by the `plot_population` task:"
   ]
  },
  {
   "cell_type": "code",
   "id": "863794df-ddf0-4c41-8b4f-6fcadb2ea30e",
   "metadata": {},
   "source": [
    "fit_results_per_qubit = analysis_workflow_results.tasks[\"fit_data\"].output\n",
    "ramsey_figures_per_qubit = analysis_workflow_results.tasks[\"plot_population\"].output"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f4838b07-8aed-42fb-a180-61176827af6c",
   "metadata": {},
   "source": [
    "We can access the qubit parameters extracted by the analysis from the output of the analysis workflow. Notice that the analysis workflow collects both the original qubit parameters with which the experiment was run (`old_parameter_values`) and the new ones extracted from the analysis (`new_parameter_values`)."
   ]
  },
  {
   "cell_type": "code",
   "id": "22fab633-de7d-4d9c-b64d-b2498ba254af",
   "metadata": {},
   "source": [
    "from pprint import pprint\n",
    "\n",
    "qubit_parameters = analysis_workflow_results.output\n",
    "pprint(qubit_parameters)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d0ac6950-8137-4f2e-b4db-c0415b5d5231",
   "metadata": {},
   "source": [
    "### Manually Updating the Qubit Parameters\n",
    "\n",
    "The run above did not update the qubit parameters with the values in `qubit_parameters[\"new_parameter_values\"]` because updating is disabled by default (we will see in the next section how to enable it via the experiment-workflow options). We can check this by inspecting the `resonance_frequency_ge` parameter of the qubit, which will still have the original value collected by the analysis in `qubit_parameters[\"old_parameter_values\"]`:"
   ]
  },
  {
   "cell_type": "code",
   "id": "61af8590-f0af-48e4-99b1-e5819411b6f0",
   "metadata": {},
   "source": [
    "qubits[0].parameters.resonance_frequency_ge"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "In practice, we sometimes want to disable automatic updating if we are not sure that the experiment runs correctly. In this case, we can still update the qubit parameters manually after the experiment has run using the `update_qpu` task:",
   "id": "431e185771038068"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "ramsey.update_qpu(qpu, qubit_parameters[\"new_parameter_values\"])",
   "id": "b7909fc8559ef649"
  },
  {
   "cell_type": "markdown",
   "id": "8745e2b3-72a7-491e-b3f2-73cc7ce4cf81",
   "metadata": {},
   "source": [
    "Similarly, if we had accidentally updated our qubit parameters during the experiment run, we can revert them using the same task and `old_parameter_values`:"
   ]
  },
  {
   "cell_type": "code",
   "id": "612d4d59-df7b-4d07-b6fa-7de14476e9d1",
   "metadata": {},
   "source": "ramsey.update_qpu(qpu, qubit_parameters[\"old_parameter_values\"])",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "18ce0f6b-d3a1-47f8-86f4-72b9d62c7515",
   "metadata": {},
   "source": [
    "## Change the options"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912746ae-29ea-4365-9d29-375b4e073184",
   "metadata": {},
   "source": [
    "We can change the options of the ramsey experiment `Workflow` by using the options feature `Workflows` (see the Options tutorial in LabOne Q Core for more details). \n",
    "\n",
    "Let's start by creating the `Workflow` options:"
   ]
  },
  {
   "cell_type": "code",
   "id": "a35ac457-67f0-422a-a89a-0eaf9d8c18a8",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "options = ramsey.experiment_workflow.options()\n",
    "options"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b9adab14-60f4-48c5-9f2c-ff08800573c7",
   "metadata": {},
   "source": [
    "Using `workflow.show_fields`, you can also read a description of each of the options fields, as well as their default values and the tasks that use them within the Ramsey experiment workflow."
   ]
  },
  {
   "cell_type": "code",
   "id": "5541d0b2-9cca-4888-8537-b7de4f265fe2",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "workflow.show_fields(options)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "58eb805f-e41e-40fe-8f2b-3bae328f9d65",
   "metadata": {},
   "source": [
    "Note that the experiments in the Applications Library collect the acquired data in an instance of the new results class, `RunExperimentResults`. To return an instance of the standard LabOne Q `Results`, you can set `options.return_legacy_results(True)`. \n",
    "\n",
    "Here, we specify new values for some of our options. Note that below, we are changing the value of these options fields for all the tasks inside the Ramsey workflow. To change the options for only a subset of the tasks, see the Options tutortial in the LabOne Q core manual."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "options.count(2048)  # change the counts\n",
    "options.use_cal_traces(False)  # remove the calibration traces\n",
    "options.update(True)  # the experiment workflow updates the qubit frequency\n",
    "# and T2_star time with the new values from the analysis"
   ],
   "id": "64e2838243b7654f"
  },
  {
   "cell_type": "markdown",
   "id": "f3edb025-5471-4865-82d6-9b973ae376b9",
   "metadata": {},
   "source": [
    "Inspect the current values of an options field:"
   ]
  },
  {
   "cell_type": "code",
   "id": "b0a052ab-0b2d-4bb0-9d7e-65970658cfa0",
   "metadata": {},
   "source": [
    "options.count"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f826c4de-c437-4db5-be29-1a55abd3c189",
   "metadata": {},
   "source": [
    "Run the `Workflow` with these options. Here, we also run the Ramsey experiment on all the 6 qubits in parallel."
   ]
  },
  {
   "cell_type": "code",
   "id": "d4a9252a-025f-4202-a7fd-0da4ef9faf44",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "ramsey_workflow_result_options = ramsey.experiment_workflow(\n",
    "    session=session,\n",
    "    qpu=qpu,\n",
    "    qubits=qubits,\n",
    "    delays=[np.linspace(0, 20e-6, 51) for q in qubits],\n",
    "    detunings=[0.67e6 for q in qubits],\n",
    "    options=options,  # pass the options\n",
    ").run()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "be0ab2fe-66c1-4464-a04e-3978075e3957",
   "metadata": {},
   "source": [
    "If we inspect the simulated pulse sequence, we'll notice that the pulses are executed in parallel on all the qubits in the expeirment and that the calibration traces are no longer there."
   ]
  },
  {
   "cell_type": "code",
   "id": "dc9d2cb3-e0e5-45e2-af96-928faf4eb3e4",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "from laboneq.contrib.example_helpers.plotting.plot_helpers import plot_simulation\n",
    "\n",
    "plot_simulation(\n",
    "    ramsey_workflow_result_options.tasks[\"compile_experiment\"].output,\n",
    "    signal_names_to_show=[\"drive\"],\n",
    "    start_time=0,\n",
    "    length=50e-6,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "967ca610-3d7f-4928-ba58-8d69e40d7e16",
   "metadata": {},
   "source": [
    "## QPU temporary parameters\n",
    "\n",
    "The QPU, together with its topology, contains the source of ground truth for an experiment and the best state of knowledge of the quantum system that is being operated. This means that the parameters of the quantum elements and topology edges in the QPU define the configuration used by all the experiments in the Applications Library. To learn more about the QPU topology, check out the [tutorial in the LabOne Q core manual](https://docs.zhinst.com/labone_q_user_manual/core/functionality_and_concepts/04_quantum_processing_unit/tutorials/02_qpu_topology.html).\n",
    "\n",
    "It is possible to run an experiment workflow using quantum elements and topology edges with temporarily modified parameters. This is useful for testing or debugging purposes. To do this, we can copy the parameters of the quantum element and/or topology edge and then modify the desired (sub-)parameters. The temporary parameters are then passed to the experiment workflow as a dictionary. \n",
    "\n",
    "For quantum elements, the dictionary key is the quantum element UID. For topology edges, the dictionary key is the edge tuple `(tag, source node UID, target node UID)`. The dictionary value is either a modified `QuantumParameters` instance or a modified parameter dictionary. To demonstrate this, let's run the Ramsey experiment workflow with a set of temporary quantum element parameters."
   ]
  },
  {
   "cell_type": "code",
   "id": "1b16a71c",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "temporary_parameters = qubits[0].parameters.copy()\n",
    "temporary_parameters.ge_drive_length = 1000e-9  # 51ns in the original qubit\n",
    "\n",
    "result_unmodified = ramsey.experiment_workflow(\n",
    "    session=session,\n",
    "    qpu=qpu,\n",
    "    qubits=qubits[0],\n",
    "    delays=np.linspace(0, 20e-6, 51),\n",
    "    detunings=0.67e6,\n",
    ").run()\n",
    "\n",
    "result_modified = ramsey.experiment_workflow(\n",
    "    session=session,\n",
    "    qpu=qpu,\n",
    "    qubits=qubits[0],\n",
    "    # In this workflow, we pass temporary parameters:\n",
    "    temporary_parameters={\n",
    "        # Here, we pass the modified `QuantumParameters` instance:\n",
    "        qubits[0].uid: temporary_parameters\n",
    "        # Alternatively, we could have passed a modified parameter dictionary instead:\n",
    "        # qubits[0].uid: {\"ge_drive_length\": 1000e-9}\n",
    "        # If there was a topology edge, we could modify its parameters in a similar way:\n",
    "        # (\"example_tag\", qubits[0].uid, qubits[1].uid): temporary_parameters\n",
    "    },\n",
    "    delays=np.linspace(0, 10e-6, 51),\n",
    "    detunings=1e6,\n",
    ").run()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6abf4bb0",
   "metadata": {},
   "source": [
    "# Compare the two pulse sequences\n",
    "from laboneq.contrib.example_helpers.plotting.plot_helpers import plot_simulation\n",
    "\n",
    "plot_simulation(\n",
    "    result_unmodified.tasks[\"compile_experiment\"].output,\n",
    "    signal_names_to_show=[\"drive\", \"measure\"],\n",
    "    start_time=0,\n",
    "    length=5e-6,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "eb678840",
   "metadata": {},
   "source": [
    "plot_simulation(\n",
    "    result_modified.tasks[\"compile_experiment\"].output,\n",
    "    signal_names_to_show=[\"drive\", \"measure\"],\n",
    "    start_time=0,\n",
    "    length=5e-6,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2ff99e0f-c8ec-4899-af3f-4dae47640c4f",
   "metadata": {},
   "source": [
    "## Debugging experiment Workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e0843a",
   "metadata": {},
   "source": [
    "### Inspect after an error\n",
    "\n",
    "If an error occurs during the execution of the experiment `Workflow`, we can inspect the tasks that have run up to the task that produced the error using `recover()`. This is particularly useful to inspect the experiment pulse sequence in case of a compilation or measurement error.\n",
    "\n",
    "Let's introduce a run-time error by exceeding the waveform memory."
   ]
  },
  {
   "cell_type": "code",
   "id": "35483101",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# here we catch the exception so that the notebook can keep executing\n",
    "try:\n",
    "    ramsey_result_error = ramsey.experiment_workflow(\n",
    "        session=session,\n",
    "        qpu=qpu,\n",
    "        qubits=qubits[0],\n",
    "        delays=np.linspace(0, 50e-6, 10001),\n",
    "        detunings=0.67e6,\n",
    "    ).run()\n",
    "except LabOneQException as e:\n",
    "    print(\"ERROR: \", e)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "76d6b2bc",
   "metadata": {},
   "source": [
    "ramsey_result_error = ramsey.experiment_workflow.recover()\n",
    "for t in ramsey_result_error.tasks:\n",
    "    print(t)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b7674c71-89a6-4eb1-89c8-971f6c59907d",
   "metadata": {},
   "source": [
    "Inspect the experiment section tree by calling:\n",
    "\n",
    "```python\n",
    "ramsey_result_error.tasks[\"create_experiment\"].output\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac6ccda-8706-444d-89f7-358693788605",
   "metadata": {},
   "source": [
    "### Run until a task"
   ]
  },
  {
   "cell_type": "code",
   "id": "1e66850c-c16c-468d-99de-53ab3d7337fe",
   "metadata": {},
   "source": [
    "ramsey_result_partial = ramsey.experiment_workflow(\n",
    "    session=session,\n",
    "    qpu=qpu,\n",
    "    qubits=qubits[0],\n",
    "    delays=np.linspace(0, 50e-6, 50),\n",
    "    detunings=0.67e6,\n",
    ").run(until=\"compile_experiment\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b6edbe60-711a-4b90-ac63-1ee7365816aa",
   "metadata": {},
   "source": [
    "for task in ramsey_result_partial.tasks:\n",
    "    print(task)"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
