{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a workflow guide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a simple workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import relevant objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from laboneq_applications import workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@workflow.task\n",
    "def measure() -> int:\n",
    "    return 100\n",
    "\n",
    "\n",
    "@workflow.task\n",
    "def analyze(measurement_result: int, threshold: int) -> bool:\n",
    "    return measurement_result < threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the workflow\n",
    "\n",
    "In this section we go through the process of combining our predefined tasks into a\n",
    "single workflow.\n",
    "\n",
    "A workflow in itself should be as simple as possible and it should not contain any complex\n",
    "operations. Most operations should happen within the tasks.\n",
    "\n",
    "A workflow can be defined by decorating a Python function with `@workflow` decorator.\n",
    "\n",
    "#### Important remarks\n",
    "\n",
    "When a function is marked as a `workflow`, it has some limitations to a normal Python\n",
    "execution flow:\n",
    "\n",
    "* Only functions marked as tasks should be called within a workflow definition\n",
    "* Using Python statements (`if`, `else`, `for`, etc.) should not be used in the Workflow, however they can be used freely in tasks.\n",
    "\n",
    "The reasons for above limitations is to ensure that a graph of dependencies between tasks\n",
    "can be created and the `Workflow` can then fully control the execution flow.\n",
    "\n",
    "#### Workflow references\n",
    "\n",
    "While the workflow is being constructed, the actual variables (workflow inputs, task outputs) are replaced\n",
    "with a `Reference` object that then connects the producing and receiving ends of an variable.\n",
    "\n",
    "By default `Reference` supports only a subset of default Python operations, for example, `__getitem__` and\n",
    "`__getattr__`. The supported operations can be seen from `Reference` documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@workflow.workflow\n",
    "def experiment(threshold: int):\n",
    "    measurement = measure()\n",
    "    analyze(measurement, threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate and run the workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wf = experiment(threshold=101)\n",
    "wf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = wf.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspecting the tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several ways to get the individual tasks from the `WorkflowResult`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.tasks[1], result.tasks[\"analyze\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specific task lookup with indexing\n",
    "\n",
    "The first argument is the name of the task and the second is an integer or a\n",
    "`slice`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.tasks[\"analyze\", :]  # All tasks named 'analyze'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.tasks[\"analyze\", 0]  # First task entry for 'analyze'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspecting individual task information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task output\n",
    "result.tasks[\"analyze\"].output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task input\n",
    "result.tasks[\"analyze\"].input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect a workflow that has failed\n",
    "\n",
    "In case there is an error during the execution of a workflow, we can still inspect the tasks that have run up to the task that triggered the error using `recover()`. Note that `recover()` stores only one execution result and can only be called once; a second call to `recover()` raises an exception.\n",
    "\n",
    "For experiment workflows, this is useful for debugging a failed compilation task by inspecting the experiment sequence produced by the previous task. \n",
    "\n",
    "In this example, we will add an assertion error to the `analyze` task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@workflow.task\n",
    "def measure() -> int:\n",
    "    return 100\n",
    "\n",
    "\n",
    "@workflow.task\n",
    "def analyze(measurement_result: int, threshold: int) -> bool:\n",
    "    # let's add an error in this task\n",
    "    if not (measurement_result >= 100 and threshold >= 100):\n",
    "        raise RuntimeError(\"Something went wrong.\")\n",
    "    return measurement_result < threshold\n",
    "\n",
    "\n",
    "@workflow.workflow\n",
    "def experiment(threshold: int):\n",
    "    measurement = measure()\n",
    "    analyze(measurement, threshold)\n",
    "    workflow.return_(\"PASS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = experiment(99).run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recovered_result = experiment.recover()\n",
    "recovered_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that the measure task returns a result that is >= 100\n",
    "recovered_result.tasks[\"measure\"].output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the value of the threshold passed to the taskbook\n",
    "recovered_result.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we know we have to increase the value of the threshold\n",
    "result = experiment(101).run()\n",
    "result.output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run a partial Workflow\n",
    "\n",
    "In some cases during development, only parts of a workflow need to be executed.\n",
    "For this reason, workflows can be \n",
    "executed until a specific `task` within the workflow.\n",
    "\n",
    "In the example below, we will use the previously defined workflow and execute only\n",
    "the `measure()` part of the workflow to validate everything is working as expected before\n",
    "continuing to `analyze()` and finishing the workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we run the experiment workflow with an `until` argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = experiment(100)\n",
    "partial_result = exp.run(until=\"measure\")\n",
    "partial_result.tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the partial result\n",
    "print(partial_result.tasks)\n",
    "print(partial_result.tasks[0].output)\n",
    "print(partial_result.output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After checking that our simple task works as expected, the workflow can be resumed\n",
    "by calling `.resume()` without the `until` argument.\n",
    "\n",
    "The already-executed tasks are not executed again, and their results are used in the following\n",
    "workflow execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = exp.resume()\n",
    "print(result.tasks)\n",
    "print(result.output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
