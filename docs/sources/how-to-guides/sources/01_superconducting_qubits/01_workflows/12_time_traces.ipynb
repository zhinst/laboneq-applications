{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAW Time Traces for Qubit Readout Optimal Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Prerequisites\n",
    "This guide assumes you have a configured `DeviceSetup` as well as `Qubit` objects with assigned parameters. Please see [Getting Started tutorial](../../../../tutorials/sources/getting_started.ipynb) if you need to create your setup and qubits for the first time. \n",
    "\n",
    "You can run this notebook on real hardware in the lab. However, if you don't have the hardware at your disposal, you can also run the notebook \"as is\" using an emulated session (see below). \n",
    "\n",
    "If you are just getting started with the LabOne Q Applications Library, please don't hesitate to reach out to us at info@zhinst.com."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this how-to guide, you will measure the raw time traces of the readout signal coming back to the Quantum Analyzer unit of a SHFQC or SHFQA, before demodulation with the digital oscillator signal. This can be done here for every qubit in the sample for every possible combination of the states $\\ket{g}$, $\\ket{e}$ and $\\ket{f}$. In a future version of the guide, the raw time traces will be used to determine the optimal integration kernel for qubit readout, achieving maximal distinguishability between different qubit states. \n",
    "\n",
    "To distinguish between $n$ different states, a total of $n(n-1)/2$ integration weights $w_{i, j}(t)$ is required, with $i, j \\in\\left\\{0, 1, ..., n-1\\right\\}$ and $j>i$. At each time $t$, the optimal integration weights can be calculated as $w_{i, j}(t) = \\overline{r_i(t) - r_j(t)}$, where $r_i$ denotes the time trace with the qubit in state $i$ and the horizontal bar represents the complex conjugate. Note that in general only $n-1$ different integration weights need to be explicitly measured since the remaining ones can be obtained from the pairwise difference of the measured weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "\n",
    "You'll start by importing the time-traces experiment workflows from `laboneq_applications`, as well as `laboneq.simple` and a demo QPU and device setup to run in emulation mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from laboneq.contrib.example_helpers.plotting.plot_helpers import plot_simulation\n",
    "from laboneq.simple import *\n",
    "\n",
    "from laboneq_applications.experiments import time_traces\n",
    "from laboneq_applications.qpu_types.tunable_transmon.demo_qpus import demo_platform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QPU and Device Setup\n",
    "\n",
    "You'll generate six qubits with pre-defined parameters, as well as a `Device_Setup` consisting of a SHFQC+, HDAWG, and PQSC. If you already have your own `DeviceSetup` and qubits configured, you'll instead initialize the session using your setup as shown in the [Getting Started tutorial](../../../../tutorials/sources/getting_started.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_platform = demo_platform(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, you'll connect to the `Session`. Here we connect to an emulated one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = Session(my_platform.setup)\n",
    "session.connect(do_emulation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a `FolderStore` for Saving Data\n",
    "\n",
    "The experiment `Workflows` can automatically save the inputs and outputs of all their tasks to the folder path we specify when instantiating the `FolderStore`. Here, we choose the current working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import FolderStore from the `workflow` namespace of LabOne Q, which was imported\n",
    "# from `laboneq.simple`\n",
    "from pathlib import Path\n",
    "\n",
    "folder_store = workflow.logbook.FolderStore(Path.cwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We disable saving in this guide. To enable it, simply run `folder_store.activate()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_store.deactivate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the Experiment Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll now make the experiment workflow and run. For more details on what experiment workflows are and what tasks they execute, see the [Experiment Workflows tutorial](../../../../tutorials/sources/experiment_workflows.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first create the options class for the time-traces experiment and inspect it using the tree view of the option fields per task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "options = time_traces.experiment_workflow.options()\n",
    "options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, alternatively, using the `show_fields` function from the `workflow` namespace of LabOne Q, which was imported from `laboneq.simple`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.show_fields(options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that, unless we change it:\n",
    "\n",
    "- the experiment is run in `AcquisitionType.RAW` and `AveragingMode.CYCLIC`, using 1024 averages (`count`)\n",
    "- the analysis workflow will run automatically (`do_analysis=True`)\n",
    "- the figures produced by the analysis are automatically closed (`close_figures=False`)\n",
    "- the qubit parameters will not be updated (`update=False`)\n",
    "\n",
    "Here, let's disable closing the figures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options.close_figures(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we run the experiment workflow on the first two qubits in parallel, for the states $|g\\rangle$, $|e\\rangle$, and $|f\\rangle$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our qubits live here in the demo setup:\n",
    "qubits = my_platform.qpu.qubits\n",
    "\n",
    "exp_workflow = time_traces.experiment_workflow(\n",
    "    session=session,\n",
    "    qpu=my_platform.qpu,\n",
    "    qubits=[qubits[0], qubits[1]],\n",
    "    states=[\"g\", \"e\", \"f\"],\n",
    "    options=options\n",
    ")\n",
    "\n",
    "workflow_results = exp_workflow.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspect the Tasks That Were Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for t in workflow_results.tasks:\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As multiplexed readout is not supported in `AcquisitionType.RAW`, we run a separate experiment for each qubit. Hence, we have as many runs of the `create_experiment`, `compile_experiment`, and `run_experiment` tasks as the number of qubits on which the experiment was executed, which in this case is two. The acquired results from the individual runs are then combined into a single instance of `RunExerimentResults` in the task `combine_results`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspect the Output Simulation\n",
    "\n",
    "Let's inspect the simulated output for the compiled experiment corresponding to the first qubit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "compiled_exps_q0 = [t.output for t in workflow_results.tasks[\"compile_experiment\", :] if t.index[0] == \"q0\"]\n",
    "for compiled_experiment in compiled_exps_q0:\n",
    "    plot_simulation(compiled_experiment, start_time=0, length=10e-6, signal_names_to_show=[\"drive\", \"drive_ef\", \"measure\", \"acquire\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspecting the Source Code of the Pulse-Sequence Creation Task\n",
    "\n",
    "You can inspect the source code of the `create_experiment` task defined in `ramsey` to see how the experiment pulse sequence is created using quantum operations. To learn more about the latter, see the Quantum Operations tutorial (add link)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "time_traces.create_experiment.src"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To learn more about how to work with experiment `Workflows`, check out the [Experiment Workflows tutorial](../../../../tutorials/sources/experiment_workflows.ipynb).\n",
    "\n",
    "Here, let's briefly inspect the analysis-workflow results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis Results\n",
    "\n",
    "Let's check what tasks were run as part of the analysis workflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_workflow_results = workflow_results.tasks[\"analysis_workflow\"]\n",
    "for t in analysis_workflow_results.tasks:\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can access the qubit parameters extracted by the analysis from the output of the analysis-workflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(analysis_workflow_results.output)  # noqa: T203"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out the [Experiment Workflows tutorial](../../../../tutorials/sources/experiment_workflows.ipynb) to see how you can manually update the qubit parameters to these new values, or reset them to the old ones. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! You've now run your resonator-spectroscopy experiment. Check out other experiments in this manual to keep characterizing your qubits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
